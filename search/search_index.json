{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Querying the CustomerSales DW \u00b6 Marco Langenhuizen, Fontys ICT & Business, May 2017 Introduction \u00b6 This SQL exercise book consists of a demo part and an exercise part. In the demo part you will find annotated SQL queries that can be used as examples or prototypes for the exercises you have to solve yourselves. The idea is that if you understand the demo queries, you should be able to come up with a working solution for any of the exercise queries. They will be challenging though. In class some of the demo queries will be live demoed. In addition, you can ask anything you want about any demo query. You won't get direct help on the exercise queries. It is your learning job to struggle your way through them with everything you know from the demo queries. In addition to the edX Querying with Transact-SQL course where this exercise book is based on, you might want to look at the Mode Analytics SQL Tutorial for some more background on SQL or any other source of your preference. Often a SQL result in table format is not easy to understand. That's why you're encouraged to use Excel to visualize the results of your queries. With Excel's Get&Transform functionality (formerly known as Power Query), it is very easy to reuse the queries in Excel after you've tested them in SSMS. You can then create a visual based on the resulting table in Excel. Data model \u00b6","title":"Home"},{"location":"#querying-the-customersales-dw","text":"Marco Langenhuizen, Fontys ICT & Business, May 2017","title":"Querying the CustomerSales DW"},{"location":"#introduction","text":"This SQL exercise book consists of a demo part and an exercise part. In the demo part you will find annotated SQL queries that can be used as examples or prototypes for the exercises you have to solve yourselves. The idea is that if you understand the demo queries, you should be able to come up with a working solution for any of the exercise queries. They will be challenging though. In class some of the demo queries will be live demoed. In addition, you can ask anything you want about any demo query. You won't get direct help on the exercise queries. It is your learning job to struggle your way through them with everything you know from the demo queries. In addition to the edX Querying with Transact-SQL course where this exercise book is based on, you might want to look at the Mode Analytics SQL Tutorial for some more background on SQL or any other source of your preference. Often a SQL result in table format is not easy to understand. That's why you're encouraged to use Excel to visualize the results of your queries. With Excel's Get&Transform functionality (formerly known as Power Query), it is very easy to reuse the queries in Excel after you've tested them in SSMS. You can then create a visual based on the resulting table in Excel.","title":"Introduction"},{"location":"#data-model","text":"","title":"Data model"},{"location":"demoqueries/","text":"Demo Queries \u00b6 1. Total Revenue \u00b6 Calculate revenue of all registered sales transactions. In order to properly value the benefits of having crated a dimensional model of the contents of a transactional model, we first show solutions for this query on both the transactional and the dimensional database. On transactional db CustomerSales \u00b6 The idea is to first calculate the value of each order line and then sum up those values but we first have to retrieve the price a product had when the order was placed. select sum ( quantity * price ) as revenue from custorder o join orderline l on o . orderno = l . orderno join productprice p on p . prodno = l . prodno and orderdate between startdate and enddate ; On dimensional db CustomerSalesDW \u00b6 As the dimensional database is for reporting and analysis purposes only (we won't use it to change data as for instance changing a product's price), we've already calculated the proper order line value upon creating the database. This makes many of our (reporting) queries so much easier! select sum ( linetotal ) as revenue from factSales ; 2. Revenue per region \u00b6 Calculate revenue per sales region of all registered sales transactions. On transactional db CustomerSales \u00b6 In order to get each customer's region code, you have to look it up in the sales region table using part of the customer address as lookup key: select regioncode , sum ( quantity * price ) as revenue from salesregion r join customer c on left ( address , 4 ) between pcbegin and pcend join custorder o on c . custno = o . custno join orderline l on o . orderno = l . orderno join productprice p on p . prodno = l . prodno and orderdate between startdate and enddate group by regioncode ; On dimensional db CustomerSalesDW \u00b6 In the dimensional version of CustomerSales, the Customer and SalesRegion tables have been flattened into a single dimDimension table. This leads to much easier retrieval: select regioncode , sum ( linetotal ) as revenue from factSales s join dimCustomer c on s . custno = c . custno group by regioncode ; 3. Monthly revenue \u00b6 Calculate monthly revenue per product category in 2016. On transactional db CustomerSales \u00b6 select month ( orderdate ) as monthno , catcode , sum ( quantity * price ) as revenue from custorder o join orderline l on o . orderno = l . orderno join product p on p . prodno = l . prodno join productprice pp on pp . prodno = l . prodno and orderdate between startdate and enddate where orderdate between '2016-01-01' and '2016-12-31' group by month ( orderdate ), catcode order by month ( orderdate ), catcode ; On dimensional db CustomerSalesDW \u00b6 select monthno , monthname , catcode , sum ( linetotal ) as revenue from factSales s join dimDate on orderdate = dat join dimProduct p on p . prodno = s . prodno where year = 2016 group by monthno , monthname , catcode ; 4. Sales transactions per month \u00b6 Calculate for each customer the number of sales transactions per month in 2016. Show months without transactions as 0. I hope I have convincingly made my case that it is easier to query a dimensional database than a transactional database. All remaining queries are defined on the dimensional database. In one of the earlier queries, months without sales for any of the product categories, wouldn't be visible. For reporting purposes, this is often undesirable. Instead of being invisible, months without sales should be presented as months with 0 revenue. Likewise, months without transactions should be presented as months with 0 transactions. Using a standard inner join won't do the job: it leaves out months without transactions: -- wrong result! select month ( orderdate ) as monthno , c . custno , name , count ( distinct orderno ) as [ # transactions ] from dimCustomer c join factSales s on s . custno = c . custno where year ( orderdate ) = 2016 group by month ( orderdate ), c . custno , name order by name , monthno ; Note that factSales has order line granularity. In order to get the number of transactions, we have to count the number of unique (distinct) order numbers. We have to use an outer join to preserve month without sales. As a result, we can't use the orderdate from factSales and that's exactly the reason we've created a date dimension in our model. A first (wrong) attempt could be: -- wrong result! select monthno , c . custno , name , count ( distinct orderno ) as [ # transactions ] from dimCustomer c left join factSales s on s . custno = c . custno left join dimDate on orderdate = dat where year = 2016 group by monthno , c . custno , name order by name , monthno ; Run the query and explain why this is not working. The following query is a working solution. It cross joins dimCustomer with dimDate in order to create all possible customer-month combinations. The result of the cross join is the (left) outer joined with factSales and thus effectively preserve all customer-month combination without sales transactions. select monthno , c . custno , name , count ( distinct orderno ) as [ # transactions ] from dimCustomer c cross join dimDate left join factSales s on s . custno = c . custno and orderdate = dat where year = 2016 group by monthno , c . custno , name order by name , monthno ; 5. Monthly product revenue \u00b6 Calculate monthly revenue of zwezerik (product: sweetbread) in 2016. Show months without sales as 0. A working solution in the spirit of previous solution would be: select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 and proddesc = 'zwezerik' group by monthno , monthname order by monthno ; That's it, working. My advise would be to stick to this pattern of solving this kind of questions. If you're interested, an alternative solution would be: select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from factSales s join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' right join dimDate on orderdate = dat where year = 2016 group by monthno , monthname order by monthno ; This is an interesting query. Why did we use a right join instead of the more common left join? Let's set up a solution using left joins: -- wrong result! select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from dimDate left join factSales s on orderdate = dat left join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' where year = 2016 group by monthno , monthname order by monthno ; As joins evaluate from left to right, we obviously have to left join dimProduct as well in order to keep preserving the empty months from dimDate. However, the query does not return the correct results. Analyzing the results will learn you that the filter on proddesc (selecting 'zwezerik' only) hasn't worked out. The problem is that dimProduct is left joined with the result of the first left join. This means that all factSales lines will be in the result set even if there were no 'zwezerik' sales involved. And as line totals are summed from the factSales table, this obviously leads to the wrong result. As a simple insight in the problem, you could add a count on linetotal and a count on proddesc: -- wrong result! select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue , count ( linetotal ) as [ # linetotal values ], count ( proddesc ) as [ # zwezerik lines ] from dimDate left join factSales s on orderdate = dat left join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' where year = 2016 group by monthno , monthname order by monthno ; Having different values for the number of factsales lines and order lines that involved 'zwezerik', means that you are going to end up with the wrong result. These mistakes are very difficult to spot as you get a seemingly proper result. It really demands a good understanding of SQL to avoid such mistakes! It is now easy to understand that a solution with a cross join or a right join as above is preferable over a left join solution. Here is a working left join solution: select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from dimDate left join ( factSales s join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' ) on orderdate = dat where year = 2016 group by monthno , monthname order by monthno ; Create a column chart of the result in Excel. Here' s a short digression about creating Excel charts from SQL query results. To create an Excel visual of the result of this query, we use the following procedure: Create a database connection to the SQL Server database using Power Query (Get & Transform). Open Advanced Options in the connection dialog and past your tested T-SQL query. Adapt your query such that the data series you want to visualize are in separate columns. (We often refer to this format as pivot format.) Load the query results to a table in a new worksheet. Use this table as a chart feeder for a suitable Excel chart. Why not using a pivot table with pivot charts? First of all a pivot table with pivot charts is a fine solution and indeed much more common than executing a query on the database for each visual. However, pivot tables (and I mean traditional pivot tables, not Power Pivot pivot tables) come with their disadvantages: not all available chart types are available as pivot chart. Pivot tables are always based on a single table. This means that you have to create a single table of all data you want to report on. Usually this means that you have to create a full join of all the data in your database. If you want to preserve all possible dimension combinations without sales (as we did for only months in previous query), this rapidly leads to a huge table. Even in our very small CustomerSales database, this leads to a table with over 2 million rows: you won't be able to load this in Excel. Wide vs. long format SQL tables and SQL query results are usually in long format. Suppose we have the following table select * from ( values ( 20 , '2017-10-21' , 103 , 6 ), ( 22 , '2017-10-21' , 103 , 4 ), ( 22 , '2017-10-21' , 101 , 2 ), ( 20 , '2017-11-24' , 103 , 4 ), ( 20 , '2017-11-24' , 102 , 3 ) ) as T ( custno , orderdate , prodno , qty ) ; This yields the following table in long format: custno orderdate prodno qty 20 2017-10-21 103 6 22 2017-10-21 103 4 22 2017-10-21 101 2 20 2017-11-24 103 4 20 2017-11-24 102 3 Before creating the chart feeder data, it is necessary to think about what and how you want to present in your visual. Suppose I want to present for each customer, for each month a column bar representing the quantity sold if the specific product. I want customers on the X-axis, months on slicers and products as series. The same table in wide format with products on columns, would yield: with cte as ( select * from ( values ( 20 , '2017-10-21' , 103 , 6 ), ( 22 , '2017-10-21' , 103 , 4 ), ( 22 , '2017-10-21' , 101 , 2 ), ( 20 , '2017-11-24' , 103 , 4 ), ( 20 , '2017-11-24' , 102 , 3 ) ) as T ( custno , orderdate , prodno , qty ) ) select custno , datename ( m , orderdate ) as mnth , sum ( case when prodno = 101 then qty else 0 end ) as onions , sum ( case when prodno = 102 then qty else 0 end ) as beans , sum ( case when prodno = 103 then qty else 0 end ) as potatoes , sum ( case when prodno = 104 then qty else 0 end ) as cabbage from cte group by custno , datename ( m , orderdate ) ; custno orderdate onions beans potatoes cabbage 20 2017-10-21 0 0 6 0 22 2017-10-21 2 0 4 0 20 2017-10-24 0 3 4 0 When table are to be presented to humans, the wide format tends to be better as it is more compact. Excel wants its chart feeders to be in wide format too. This holds for both regular charts and pivot charts. As pivot charts are based on pivot tables, the chart feeder is almost always in wide format. Sometimes Excel can express its own will when visualizing data from a chart feeder. The result may not always be to your liking. However, using the Select Data command from the Chart Tools > Design ribbon will always lead to the visual you had in mind. 6. Compare revenue figures \u00b6 Compare monthly zwezerik revenue in 2016 and 2015. We get a straightforward solution by slightly adapting the previous query: select year , monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from factSales s join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' right join dimDate on orderdate = dat where year in ( 2016 , 2015 ) group by year , monthno , monthname order by year , monthno ; Create a column chart of the result in Excel. For an Excel chart, it's easier to have the result in pivot format. Different columns are translated into different series in a chart; that is exactly what we want if we want to compare without using a pivot table. To get different columns, we use a case/when in the select rather than the complicated pivot table-operator. select monthno , monthname , isnull ( sum ( case year when 2015 then linetotal else 0 end ), 0 ) as rev13 , isnull ( sum ( case year when 2016 then linetotal else 0 end ), 0 ) as rev14 from factSales s join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' right join dimDate on orderdate = dat where year in ( 2016 , 2015 ) group by monthno , monthname order by monthno ; Note that we must no longer group on year if we wish to separate the year in each line of the result set. 7. Revenue as percentage of total (1) \u00b6 Calculate the monthly revenue of zwezerik in 2016 as a percentage of total revenue of that month. Zwezerik's percentual contribution to the monthly revenue is of course zwezerik's part divided by total revenue. Starting from query 5's solution, we could solve it like: select monthname , isnull ( sum ( linetotal ) / ( select sum ( linetotal ) from factSales where year ( orderdate ) = 2016 and month ( orderdate ) = monthno ), 0 ) as [ % rev ] from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 and proddesc = 'zwezerik' group by monthno , monthname order by monthno ; Here we used a so-called correlated subquery: the subquery references a column value in the outer query. As a consequence, the subquery should be re-calculated for each row in the outer query, and hence are usually expensive performance wise. 8. Revenue as percentage of total (2) \u00b6 Calculate the monthly revenue in 2016 of each product category as a percentage of total revenue of that month. This is a generalization of previous question, but now for product category instead of product A solution in line with previous solution would be: select monthname , catcode , isnull ( sum ( linetotal ) / ( select sum ( linetotal ) from factSales where year ( orderdate ) = 2016 and month ( orderdate ) = monthno ), 0 ) as [ % rev ] from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 group by monthno , monthname , catcode order by monthno ; Because of the generalization to all product categories, we can make use of a window function: select monthname , catcode , isnull ( sum ( linetotal ) / ( sum ( sum ( linetotal )) over ( partition by monthno )), 0 ) as [ % rev ] from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 group by monthno , monthname , catcode order by monthno ; Note that in the sum(sum()) construction, the outer sum() is the windows function that goes with the partition by whereas the inner sum() is the aggregate function that goes with the group by. In an Excel pivot table this query would be calculated using the % of row total measure with product category on rows. An SQL solution that mimics this pivot table solution would be: select monthname , isnull ( sum ( case when catcode = 'bio' then linetotal else 0 end ) / sum ( linetotal ), 0 ) as bio , isnull ( sum ( case when catcode = 'lux' then linetotal else 0 end ) / sum ( linetotal ), 0 ) as lux , isnull ( sum ( case when catcode = 'zuv' then linetotal else 0 end ) / sum ( linetotal ), 0 ) as zuv from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 group by monthno , monthname order by monthno ; 9. Individual vs average sales \u00b6 Compare yearly individual sales person revenue with (yearly) average sales person revenue. Show results in a chart. The difficulty in this query is that we have to mix addition for a single salesperson with addition (and averaging) for all salespersons. In other words: we have to group on year and name and on year only in the same query. This can only be established using a subquery with its own grouping context: select year ( orderdate ) as year , name as salesrep , sum ( linetotal ) as revenue , ( select sum ( linetotal ) / count ( distinct salesrep ) from factSales si where year ( si . orderdate ) = year ( so . orderdate ) ) as avgRevenue from factSales so join dimSalesPerson on salesrep = empno group by year ( orderdate ), name order by year , salesrep ; The inner query is called a correlated subquery because we link the year in the inner query to the year of the current result line in the outer query. Because of this correlation, the inner query must be evaluated for each result line in the outer query. 10. Cumulative revenue \u00b6 Calculate cumulative monthly revenue per product in 2016. Show results in a chart. First use a cross join to generate all month/product combinations. Then use a left (outer) join to preserve month/product combinations without sales: select monthno , monthname , proddesc , isnull ( sum ( linetotal ), 0 ) as revenue from dimDate cross join dimProduct p left join factSales s on s . prodno = p . prodno and orderdate = dat where year = 2016 group by monthno , monthname , proddesc ; To calculate the cumulative monthly revenue, instead of the monthly revenue, we use a window function: select monthno , monthname , proddesc , isnull ( sum ( sum ( linetotal )) over ( partition by proddesc order by monthno ), 0 ) as cumrev from dimDate cross join dimProduct p left join factSales s on s . prodno = p . prodno and orderdate = dat where year = 2016 group by monthno , monthname , proddesc ; Note the sum(sum()): the outer sum() is the window function, whereas the inner sum() is the aggregate function we used in our first step. The partition by creates a window of all lines having the same proddesc in a month/proddesc group. 11. YoY cumulative sales increase \u00b6 Calculate monthly year-over-year cumulative sales increase (percentage) for each product category in 2016. This is a combination of two previous demo queries: with cte as ( select monthno , monthname , catcode , isnull ( sum ( sum ( case year when 2015 then linetotal end )) over ( partition by catcode order by monthno ), 0 ) as cumrev13 , isnull ( sum ( sum ( case year when 2016 then linetotal end )) over ( partition by catcode order by monthno ), 0 ) as cumrev14 from dimDate cross join dimProduct p left join factSales s on s . prodno = p . prodno and orderdate = dat where year in ( 2015 , 2016 ) group by monthno , monthname , catcode ) select monthno , monthname , catcode , ( cumrev14 - cumrev13 ) / cumrev13 as [ YoY Rev Increase % ] from cte ; 12. Average of last two \u00b6 Calculate for each customer the average order value of last two orders. First generate a list of order values ordered by order date (most recent on top) select custno , orderno , orderdate , sum ( linetotal ) as ordVal from factSales group by custno , orderno , orderdate ; Then add ranking, select top 2 per customer and calculate average: with cte as ( select custno , orderno , orderdate , sum ( linetotal ) as ordVal , row_number () over ( partition by custno order by orderdate desc ) as rnr from factSales group by custno , orderno , orderdate ) select custno , avg ( ordval ) from cte where rnr <= 2 group by custno ; Alternatively with a cross apply (see also this demo for a (rather elaborate) discussion of using either a ranking or a cross apply solution): select custno , name , avg ( ordVal ) as avgOrdVal from dimCustomer c cross apply ( select top ( 2 ) sum ( linetotal ) as ordval from factSales s where s . custno = c . custno group by orderno , orderdate order by orderdate desc ) s group by custno , name ; select custno , orderdate from factSales s where ordno in ( select top ( 2 ) ordno from factSales si where si . custno = s . custno ) ; 13. Weekday revenue percentage \u00b6 Calculate for each customer the percentage of orders placed on a weekday in 2016. select custno , avg ( case when datepart ( dw , orderdate ) between 2 and 6 then 1 . 0 else 0 . 0 end ) as wkdy from factSales where year ( orderdate ) = 2016 group by custno ; 14. Ranking revenue figures \u00b6 Give a weekday ranking for February 2016 with the best selling (revenue) weekday on top. select datename ( dw , orderdate ), sum ( linetotal ) as rev , rank () over ( order by sum ( linetotal ) desc ) as rnk from factSales where orderdate between '2016-02-01' and '2016-02-28' group by datename ( dw , orderdate ) ; Looks ok, but we miss Saturday: there have been no sales on Saturday in Feb 2016. Clearly it's important to also present the days without sales. Let's fix it by outer joining with dimDate: select dayName , isnull ( sum ( linetotal ), 0 ) as rev , rank () over ( order by sum ( linetotal ) desc ) as rnk from dimDate left join factSales on orderdate = dat where dat between '2016-02-01' and '2016-02-28' group by dayName , dayInWeek order by dayInWeek ; Note that the where clause should involve the date from dimDate rather than from factSales. If not, the days without sales would have had an NULL orderDate and the line would have left out by the filter leading again to a result without days with no sales. Give a weekday ranking for February 2016 with the best selling (# transactions) weekday on top. You might think: replace the sum with a count and we're all set: -- wrong solution select datename ( dw , dat ), count ( linetotal ) as [ # tx ], rank () over ( order by count ( linetotal ) desc ) as rnk from dimDate left join factSales on orderdate = dat where dat between '2016-02-01' and '2016-02-28' group by datename ( dw , dat ), dayInWeek order by dayInWeek ; Alas, it turns out not to be that simple. factSales has order line granularity meaning that an order can have more than one line. We are only interested in the unique sales transactions: select datename ( dw , dat ), count ( distinct orderno ) as [ # tx ], rank () over ( order by count ( distinct orderno ) desc ) as rnk from dimDate left join factSales on orderdate = dat where dat between '2016-02-01' and '2016-02-28' group by datename ( dw , dat ), dayInWeek order by dayInWeek ; Even if we get the same result, the former solution is wrong. We get the same results by coincidence as there where no sales transactions with more than one row in February 2016. Change the filter to February 2015 and you see immediately that the results differ! So remember, even if you test your results, you can still have a wrong query. Testing more thoroughly (using more test sets) and above all remain being critical about your products (and those of others) is the best way to prevent mistakes and avoid ill decisions based on wrongly obtained information. 15. ABC labeling \u00b6 Calculate ABC labeling for all customers. Your top customers belong to the top 20% regarding revenue created. Your inactive customers belong to the tail 30% regarding revenue created. Attach an ABC label to all customers: label top customers A, inactive customers C and the remaining customers B. Instead of plain ranking with rank(), we now use the percent_rank() window function. As with plain ranking, ordering is key to obtain the ranking percentages you want. select custno , case when percent_rank () over ( order by sum ( linetotal )) >= 0 . 8 then 'A' when percent_rank () over ( order by sum ( linetotal )) < 0 . 3 then 'C' else 'B' end as label from factSales group by custno order by custno ; Repeating the over () clause looks a bit clumsy, but it's just how the case operator works. The percent_rank() function is a bit difficult to grasp at first. The lowest ranking group is always 0%. The highest ranking group is always m/(n-1) % where n is the number of rows (observations) and m is the number of rows with a lower value for the column you want to rank on. (Hence, we always start with 0% as no rows will have a lower value than the lowest value.) Try the query below and change some data in order to get a good understanding of the percent_rank() function. Do not just change and run, but first predict what the result should be. If the result is conform your expectation, you've probably understood. If not, your mental model is wrong and you have to do some more thinking and experimenting. select id , percent_rank () over ( order by val ) [ % rank ] from ( values ( 1 , 1 ), ( 2 , 1 ), ( 3 , 2 ), ( 4 , 3 ), ( 5 , 3 ) ) T ( id , val ) order by id ; 16. Basic statistical measures \u00b6 What is the number, max, min, mean and standard deviation of the sales value per order? with cte as ( select sum ( linetotal ) ordval from factSales group by orderno ) select count ( * ) as n , min ( ordval ) as min , max ( ordval ) as max , avg ( ordval ) as mean , stdev ( ordval ) as stdev from cte ; Create a chart feeder for a histogram of sales values per order in Excel. Best to create a simple chart feeder and let Excel do the the heavy lifting of histogramming as binning is bit of a nuisance in SQL. select sum ( linetotal ) ordval from factSales group by orderno ; 17. Revenue contribution \u00b6 Calculate the contribution to revenue (as percentage) of each product category in each region. Present as pivot with product categories on columns and region on rows. select regioncode , sum ( case when catcode = 'bio' then linetotal end ) as bio , sum ( case when catcode = 'lux' then linetotal end ) as lux , sum ( case when catcode = 'zuv' then linetotal end ) as zuv from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode ; Calculate the relative contribution to revenue (as percentage) of each product category in each region. Relative to what? To total regional revenue? To total product category revenue or to total overall revenue? In Excel pivot table terminology: as a % of Row Total, a % of Column Total or a % of Grand Total? We solve all three: -- percentage of regional revenue (% of row total) select regioncode , sum ( case when catcode = 'bio' then linetotal end ) / sum ( linetotal ) as bio , sum ( case when catcode = 'lux' then linetotal end ) / sum ( linetotal ) as lux , sum ( case when catcode = 'zuv' then linetotal end ) / sum ( linetotal ) as zuv from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode ; -- percentage of product category revenue (% of column total) select regioncode , sum ( case when catcode = 'bio' then linetotal end ) / ( select sum ( linetotal ) from dimProduct p join factSales s on s . prodno = p . prodno where catcode = 'bio' ) as bio , sum ( case when catcode = 'lux' then linetotal end ) / ( select sum ( linetotal ) from dimProduct p join factSales s on s . prodno = p . prodno where catcode = 'lux' ) as lux , sum ( case when catcode = 'zuv' then linetotal end ) / ( select sum ( linetotal ) from dimProduct p join factSales s on s . prodno = p . prodno where catcode = 'zuv' ) as bio from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode ; We can make this a bit less verbose with a common table expression: -- percentage of product category revenue (% of column total) with cte as ( select regioncode , catcode , sum ( linetotal ) as total from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode , catcode ) select regioncode , sum ( case when catcode = 'bio' then total end ) / ( select sum ( total ) from cte where catcode = 'bio' ) as bio , sum ( case when catcode = 'lux' then total end ) / ( select sum ( total ) from cte where catcode = 'lux' ) as lux , sum ( case when catcode = 'zuv' then total end ) / ( select sum ( total ) from cte where catcode = 'zuv' ) as zuv from cte co group by regioncode ; Finally the query to calculate the percentage of total revenue for each region/product category combination: -- percentage of overall revenue (% of grand total) select regioncode , sum ( case when catcode = 'bio' then linetotal end ) / ( sum ( sum ( linetotal )) over ()) as bio , sum ( case when catcode = 'lux' then linetotal end ) / ( sum ( sum ( linetotal )) over ()) as lux , sum ( case when catcode = 'zuv' then linetotal end ) / ( sum ( sum ( linetotal )) over ()) as zuv from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode ; We do not necessarily need a window function as denominator as a straightforward subquery will do as well: ... sum ( case when catcode = 'bio' then linetotal end ) / ( select sum ( linetotal ) from factSales ) as bio , ...","title":"Demo Queries"},{"location":"demoqueries/#demo-queries","text":"","title":"Demo Queries"},{"location":"demoqueries/#1-total-revenue","text":"Calculate revenue of all registered sales transactions. In order to properly value the benefits of having crated a dimensional model of the contents of a transactional model, we first show solutions for this query on both the transactional and the dimensional database.","title":"1. Total Revenue"},{"location":"demoqueries/#on-transactional-db-customersales","text":"The idea is to first calculate the value of each order line and then sum up those values but we first have to retrieve the price a product had when the order was placed. select sum ( quantity * price ) as revenue from custorder o join orderline l on o . orderno = l . orderno join productprice p on p . prodno = l . prodno and orderdate between startdate and enddate ;","title":"On transactional db CustomerSales"},{"location":"demoqueries/#on-dimensional-db-customersalesdw","text":"As the dimensional database is for reporting and analysis purposes only (we won't use it to change data as for instance changing a product's price), we've already calculated the proper order line value upon creating the database. This makes many of our (reporting) queries so much easier! select sum ( linetotal ) as revenue from factSales ;","title":"On dimensional db CustomerSalesDW"},{"location":"demoqueries/#2-revenue-per-region","text":"Calculate revenue per sales region of all registered sales transactions.","title":"2. Revenue per region"},{"location":"demoqueries/#on-transactional-db-customersales_1","text":"In order to get each customer's region code, you have to look it up in the sales region table using part of the customer address as lookup key: select regioncode , sum ( quantity * price ) as revenue from salesregion r join customer c on left ( address , 4 ) between pcbegin and pcend join custorder o on c . custno = o . custno join orderline l on o . orderno = l . orderno join productprice p on p . prodno = l . prodno and orderdate between startdate and enddate group by regioncode ;","title":"On transactional db CustomerSales"},{"location":"demoqueries/#on-dimensional-db-customersalesdw_1","text":"In the dimensional version of CustomerSales, the Customer and SalesRegion tables have been flattened into a single dimDimension table. This leads to much easier retrieval: select regioncode , sum ( linetotal ) as revenue from factSales s join dimCustomer c on s . custno = c . custno group by regioncode ;","title":"On dimensional db CustomerSalesDW"},{"location":"demoqueries/#3-monthly-revenue","text":"Calculate monthly revenue per product category in 2016.","title":"3. Monthly revenue"},{"location":"demoqueries/#on-transactional-db-customersales_2","text":"select month ( orderdate ) as monthno , catcode , sum ( quantity * price ) as revenue from custorder o join orderline l on o . orderno = l . orderno join product p on p . prodno = l . prodno join productprice pp on pp . prodno = l . prodno and orderdate between startdate and enddate where orderdate between '2016-01-01' and '2016-12-31' group by month ( orderdate ), catcode order by month ( orderdate ), catcode ;","title":"On transactional db CustomerSales"},{"location":"demoqueries/#on-dimensional-db-customersalesdw_2","text":"select monthno , monthname , catcode , sum ( linetotal ) as revenue from factSales s join dimDate on orderdate = dat join dimProduct p on p . prodno = s . prodno where year = 2016 group by monthno , monthname , catcode ;","title":"On dimensional db CustomerSalesDW"},{"location":"demoqueries/#4-sales-transactions-per-month","text":"Calculate for each customer the number of sales transactions per month in 2016. Show months without transactions as 0. I hope I have convincingly made my case that it is easier to query a dimensional database than a transactional database. All remaining queries are defined on the dimensional database. In one of the earlier queries, months without sales for any of the product categories, wouldn't be visible. For reporting purposes, this is often undesirable. Instead of being invisible, months without sales should be presented as months with 0 revenue. Likewise, months without transactions should be presented as months with 0 transactions. Using a standard inner join won't do the job: it leaves out months without transactions: -- wrong result! select month ( orderdate ) as monthno , c . custno , name , count ( distinct orderno ) as [ # transactions ] from dimCustomer c join factSales s on s . custno = c . custno where year ( orderdate ) = 2016 group by month ( orderdate ), c . custno , name order by name , monthno ; Note that factSales has order line granularity. In order to get the number of transactions, we have to count the number of unique (distinct) order numbers. We have to use an outer join to preserve month without sales. As a result, we can't use the orderdate from factSales and that's exactly the reason we've created a date dimension in our model. A first (wrong) attempt could be: -- wrong result! select monthno , c . custno , name , count ( distinct orderno ) as [ # transactions ] from dimCustomer c left join factSales s on s . custno = c . custno left join dimDate on orderdate = dat where year = 2016 group by monthno , c . custno , name order by name , monthno ; Run the query and explain why this is not working. The following query is a working solution. It cross joins dimCustomer with dimDate in order to create all possible customer-month combinations. The result of the cross join is the (left) outer joined with factSales and thus effectively preserve all customer-month combination without sales transactions. select monthno , c . custno , name , count ( distinct orderno ) as [ # transactions ] from dimCustomer c cross join dimDate left join factSales s on s . custno = c . custno and orderdate = dat where year = 2016 group by monthno , c . custno , name order by name , monthno ;","title":"4. Sales transactions per month"},{"location":"demoqueries/#5-monthly-product-revenue","text":"Calculate monthly revenue of zwezerik (product: sweetbread) in 2016. Show months without sales as 0. A working solution in the spirit of previous solution would be: select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 and proddesc = 'zwezerik' group by monthno , monthname order by monthno ; That's it, working. My advise would be to stick to this pattern of solving this kind of questions. If you're interested, an alternative solution would be: select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from factSales s join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' right join dimDate on orderdate = dat where year = 2016 group by monthno , monthname order by monthno ; This is an interesting query. Why did we use a right join instead of the more common left join? Let's set up a solution using left joins: -- wrong result! select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from dimDate left join factSales s on orderdate = dat left join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' where year = 2016 group by monthno , monthname order by monthno ; As joins evaluate from left to right, we obviously have to left join dimProduct as well in order to keep preserving the empty months from dimDate. However, the query does not return the correct results. Analyzing the results will learn you that the filter on proddesc (selecting 'zwezerik' only) hasn't worked out. The problem is that dimProduct is left joined with the result of the first left join. This means that all factSales lines will be in the result set even if there were no 'zwezerik' sales involved. And as line totals are summed from the factSales table, this obviously leads to the wrong result. As a simple insight in the problem, you could add a count on linetotal and a count on proddesc: -- wrong result! select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue , count ( linetotal ) as [ # linetotal values ], count ( proddesc ) as [ # zwezerik lines ] from dimDate left join factSales s on orderdate = dat left join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' where year = 2016 group by monthno , monthname order by monthno ; Having different values for the number of factsales lines and order lines that involved 'zwezerik', means that you are going to end up with the wrong result. These mistakes are very difficult to spot as you get a seemingly proper result. It really demands a good understanding of SQL to avoid such mistakes! It is now easy to understand that a solution with a cross join or a right join as above is preferable over a left join solution. Here is a working left join solution: select monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from dimDate left join ( factSales s join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' ) on orderdate = dat where year = 2016 group by monthno , monthname order by monthno ; Create a column chart of the result in Excel. Here' s a short digression about creating Excel charts from SQL query results. To create an Excel visual of the result of this query, we use the following procedure: Create a database connection to the SQL Server database using Power Query (Get & Transform). Open Advanced Options in the connection dialog and past your tested T-SQL query. Adapt your query such that the data series you want to visualize are in separate columns. (We often refer to this format as pivot format.) Load the query results to a table in a new worksheet. Use this table as a chart feeder for a suitable Excel chart. Why not using a pivot table with pivot charts? First of all a pivot table with pivot charts is a fine solution and indeed much more common than executing a query on the database for each visual. However, pivot tables (and I mean traditional pivot tables, not Power Pivot pivot tables) come with their disadvantages: not all available chart types are available as pivot chart. Pivot tables are always based on a single table. This means that you have to create a single table of all data you want to report on. Usually this means that you have to create a full join of all the data in your database. If you want to preserve all possible dimension combinations without sales (as we did for only months in previous query), this rapidly leads to a huge table. Even in our very small CustomerSales database, this leads to a table with over 2 million rows: you won't be able to load this in Excel. Wide vs. long format SQL tables and SQL query results are usually in long format. Suppose we have the following table select * from ( values ( 20 , '2017-10-21' , 103 , 6 ), ( 22 , '2017-10-21' , 103 , 4 ), ( 22 , '2017-10-21' , 101 , 2 ), ( 20 , '2017-11-24' , 103 , 4 ), ( 20 , '2017-11-24' , 102 , 3 ) ) as T ( custno , orderdate , prodno , qty ) ; This yields the following table in long format: custno orderdate prodno qty 20 2017-10-21 103 6 22 2017-10-21 103 4 22 2017-10-21 101 2 20 2017-11-24 103 4 20 2017-11-24 102 3 Before creating the chart feeder data, it is necessary to think about what and how you want to present in your visual. Suppose I want to present for each customer, for each month a column bar representing the quantity sold if the specific product. I want customers on the X-axis, months on slicers and products as series. The same table in wide format with products on columns, would yield: with cte as ( select * from ( values ( 20 , '2017-10-21' , 103 , 6 ), ( 22 , '2017-10-21' , 103 , 4 ), ( 22 , '2017-10-21' , 101 , 2 ), ( 20 , '2017-11-24' , 103 , 4 ), ( 20 , '2017-11-24' , 102 , 3 ) ) as T ( custno , orderdate , prodno , qty ) ) select custno , datename ( m , orderdate ) as mnth , sum ( case when prodno = 101 then qty else 0 end ) as onions , sum ( case when prodno = 102 then qty else 0 end ) as beans , sum ( case when prodno = 103 then qty else 0 end ) as potatoes , sum ( case when prodno = 104 then qty else 0 end ) as cabbage from cte group by custno , datename ( m , orderdate ) ; custno orderdate onions beans potatoes cabbage 20 2017-10-21 0 0 6 0 22 2017-10-21 2 0 4 0 20 2017-10-24 0 3 4 0 When table are to be presented to humans, the wide format tends to be better as it is more compact. Excel wants its chart feeders to be in wide format too. This holds for both regular charts and pivot charts. As pivot charts are based on pivot tables, the chart feeder is almost always in wide format. Sometimes Excel can express its own will when visualizing data from a chart feeder. The result may not always be to your liking. However, using the Select Data command from the Chart Tools > Design ribbon will always lead to the visual you had in mind.","title":"5. Monthly product revenue"},{"location":"demoqueries/#6-compare-revenue-figures","text":"Compare monthly zwezerik revenue in 2016 and 2015. We get a straightforward solution by slightly adapting the previous query: select year , monthno , monthname , isnull ( sum ( linetotal ), 0 ) as revenue from factSales s join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' right join dimDate on orderdate = dat where year in ( 2016 , 2015 ) group by year , monthno , monthname order by year , monthno ; Create a column chart of the result in Excel. For an Excel chart, it's easier to have the result in pivot format. Different columns are translated into different series in a chart; that is exactly what we want if we want to compare without using a pivot table. To get different columns, we use a case/when in the select rather than the complicated pivot table-operator. select monthno , monthname , isnull ( sum ( case year when 2015 then linetotal else 0 end ), 0 ) as rev13 , isnull ( sum ( case year when 2016 then linetotal else 0 end ), 0 ) as rev14 from factSales s join dimProduct p on p . prodno = s . prodno and proddesc = 'zwezerik' right join dimDate on orderdate = dat where year in ( 2016 , 2015 ) group by monthno , monthname order by monthno ; Note that we must no longer group on year if we wish to separate the year in each line of the result set.","title":"6. Compare revenue figures"},{"location":"demoqueries/#7-revenue-as-percentage-of-total-1","text":"Calculate the monthly revenue of zwezerik in 2016 as a percentage of total revenue of that month. Zwezerik's percentual contribution to the monthly revenue is of course zwezerik's part divided by total revenue. Starting from query 5's solution, we could solve it like: select monthname , isnull ( sum ( linetotal ) / ( select sum ( linetotal ) from factSales where year ( orderdate ) = 2016 and month ( orderdate ) = monthno ), 0 ) as [ % rev ] from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 and proddesc = 'zwezerik' group by monthno , monthname order by monthno ; Here we used a so-called correlated subquery: the subquery references a column value in the outer query. As a consequence, the subquery should be re-calculated for each row in the outer query, and hence are usually expensive performance wise.","title":"7. Revenue as percentage of total (1)"},{"location":"demoqueries/#8-revenue-as-percentage-of-total-2","text":"Calculate the monthly revenue in 2016 of each product category as a percentage of total revenue of that month. This is a generalization of previous question, but now for product category instead of product A solution in line with previous solution would be: select monthname , catcode , isnull ( sum ( linetotal ) / ( select sum ( linetotal ) from factSales where year ( orderdate ) = 2016 and month ( orderdate ) = monthno ), 0 ) as [ % rev ] from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 group by monthno , monthname , catcode order by monthno ; Because of the generalization to all product categories, we can make use of a window function: select monthname , catcode , isnull ( sum ( linetotal ) / ( sum ( sum ( linetotal )) over ( partition by monthno )), 0 ) as [ % rev ] from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 group by monthno , monthname , catcode order by monthno ; Note that in the sum(sum()) construction, the outer sum() is the windows function that goes with the partition by whereas the inner sum() is the aggregate function that goes with the group by. In an Excel pivot table this query would be calculated using the % of row total measure with product category on rows. An SQL solution that mimics this pivot table solution would be: select monthname , isnull ( sum ( case when catcode = 'bio' then linetotal else 0 end ) / sum ( linetotal ), 0 ) as bio , isnull ( sum ( case when catcode = 'lux' then linetotal else 0 end ) / sum ( linetotal ), 0 ) as lux , isnull ( sum ( case when catcode = 'zuv' then linetotal else 0 end ) / sum ( linetotal ), 0 ) as zuv from dimDate cross join dimProduct p left join factSales s on p . prodno = s . prodno and orderdate = dat where year = 2016 group by monthno , monthname order by monthno ;","title":"8. Revenue as percentage of total (2)"},{"location":"demoqueries/#9-individual-vs-average-sales","text":"Compare yearly individual sales person revenue with (yearly) average sales person revenue. Show results in a chart. The difficulty in this query is that we have to mix addition for a single salesperson with addition (and averaging) for all salespersons. In other words: we have to group on year and name and on year only in the same query. This can only be established using a subquery with its own grouping context: select year ( orderdate ) as year , name as salesrep , sum ( linetotal ) as revenue , ( select sum ( linetotal ) / count ( distinct salesrep ) from factSales si where year ( si . orderdate ) = year ( so . orderdate ) ) as avgRevenue from factSales so join dimSalesPerson on salesrep = empno group by year ( orderdate ), name order by year , salesrep ; The inner query is called a correlated subquery because we link the year in the inner query to the year of the current result line in the outer query. Because of this correlation, the inner query must be evaluated for each result line in the outer query.","title":"9. Individual vs average sales"},{"location":"demoqueries/#10-cumulative-revenue","text":"Calculate cumulative monthly revenue per product in 2016. Show results in a chart. First use a cross join to generate all month/product combinations. Then use a left (outer) join to preserve month/product combinations without sales: select monthno , monthname , proddesc , isnull ( sum ( linetotal ), 0 ) as revenue from dimDate cross join dimProduct p left join factSales s on s . prodno = p . prodno and orderdate = dat where year = 2016 group by monthno , monthname , proddesc ; To calculate the cumulative monthly revenue, instead of the monthly revenue, we use a window function: select monthno , monthname , proddesc , isnull ( sum ( sum ( linetotal )) over ( partition by proddesc order by monthno ), 0 ) as cumrev from dimDate cross join dimProduct p left join factSales s on s . prodno = p . prodno and orderdate = dat where year = 2016 group by monthno , monthname , proddesc ; Note the sum(sum()): the outer sum() is the window function, whereas the inner sum() is the aggregate function we used in our first step. The partition by creates a window of all lines having the same proddesc in a month/proddesc group.","title":"10. Cumulative revenue"},{"location":"demoqueries/#11-yoy-cumulative-sales-increase","text":"Calculate monthly year-over-year cumulative sales increase (percentage) for each product category in 2016. This is a combination of two previous demo queries: with cte as ( select monthno , monthname , catcode , isnull ( sum ( sum ( case year when 2015 then linetotal end )) over ( partition by catcode order by monthno ), 0 ) as cumrev13 , isnull ( sum ( sum ( case year when 2016 then linetotal end )) over ( partition by catcode order by monthno ), 0 ) as cumrev14 from dimDate cross join dimProduct p left join factSales s on s . prodno = p . prodno and orderdate = dat where year in ( 2015 , 2016 ) group by monthno , monthname , catcode ) select monthno , monthname , catcode , ( cumrev14 - cumrev13 ) / cumrev13 as [ YoY Rev Increase % ] from cte ;","title":"11. YoY cumulative sales increase"},{"location":"demoqueries/#12-average-of-last-two","text":"Calculate for each customer the average order value of last two orders. First generate a list of order values ordered by order date (most recent on top) select custno , orderno , orderdate , sum ( linetotal ) as ordVal from factSales group by custno , orderno , orderdate ; Then add ranking, select top 2 per customer and calculate average: with cte as ( select custno , orderno , orderdate , sum ( linetotal ) as ordVal , row_number () over ( partition by custno order by orderdate desc ) as rnr from factSales group by custno , orderno , orderdate ) select custno , avg ( ordval ) from cte where rnr <= 2 group by custno ; Alternatively with a cross apply (see also this demo for a (rather elaborate) discussion of using either a ranking or a cross apply solution): select custno , name , avg ( ordVal ) as avgOrdVal from dimCustomer c cross apply ( select top ( 2 ) sum ( linetotal ) as ordval from factSales s where s . custno = c . custno group by orderno , orderdate order by orderdate desc ) s group by custno , name ; select custno , orderdate from factSales s where ordno in ( select top ( 2 ) ordno from factSales si where si . custno = s . custno ) ;","title":"12. Average of last two"},{"location":"demoqueries/#13-weekday-revenue-percentage","text":"Calculate for each customer the percentage of orders placed on a weekday in 2016. select custno , avg ( case when datepart ( dw , orderdate ) between 2 and 6 then 1 . 0 else 0 . 0 end ) as wkdy from factSales where year ( orderdate ) = 2016 group by custno ;","title":"13. Weekday revenue percentage"},{"location":"demoqueries/#14-ranking-revenue-figures","text":"Give a weekday ranking for February 2016 with the best selling (revenue) weekday on top. select datename ( dw , orderdate ), sum ( linetotal ) as rev , rank () over ( order by sum ( linetotal ) desc ) as rnk from factSales where orderdate between '2016-02-01' and '2016-02-28' group by datename ( dw , orderdate ) ; Looks ok, but we miss Saturday: there have been no sales on Saturday in Feb 2016. Clearly it's important to also present the days without sales. Let's fix it by outer joining with dimDate: select dayName , isnull ( sum ( linetotal ), 0 ) as rev , rank () over ( order by sum ( linetotal ) desc ) as rnk from dimDate left join factSales on orderdate = dat where dat between '2016-02-01' and '2016-02-28' group by dayName , dayInWeek order by dayInWeek ; Note that the where clause should involve the date from dimDate rather than from factSales. If not, the days without sales would have had an NULL orderDate and the line would have left out by the filter leading again to a result without days with no sales. Give a weekday ranking for February 2016 with the best selling (# transactions) weekday on top. You might think: replace the sum with a count and we're all set: -- wrong solution select datename ( dw , dat ), count ( linetotal ) as [ # tx ], rank () over ( order by count ( linetotal ) desc ) as rnk from dimDate left join factSales on orderdate = dat where dat between '2016-02-01' and '2016-02-28' group by datename ( dw , dat ), dayInWeek order by dayInWeek ; Alas, it turns out not to be that simple. factSales has order line granularity meaning that an order can have more than one line. We are only interested in the unique sales transactions: select datename ( dw , dat ), count ( distinct orderno ) as [ # tx ], rank () over ( order by count ( distinct orderno ) desc ) as rnk from dimDate left join factSales on orderdate = dat where dat between '2016-02-01' and '2016-02-28' group by datename ( dw , dat ), dayInWeek order by dayInWeek ; Even if we get the same result, the former solution is wrong. We get the same results by coincidence as there where no sales transactions with more than one row in February 2016. Change the filter to February 2015 and you see immediately that the results differ! So remember, even if you test your results, you can still have a wrong query. Testing more thoroughly (using more test sets) and above all remain being critical about your products (and those of others) is the best way to prevent mistakes and avoid ill decisions based on wrongly obtained information.","title":"14. Ranking revenue figures"},{"location":"demoqueries/#15-abc-labeling","text":"Calculate ABC labeling for all customers. Your top customers belong to the top 20% regarding revenue created. Your inactive customers belong to the tail 30% regarding revenue created. Attach an ABC label to all customers: label top customers A, inactive customers C and the remaining customers B. Instead of plain ranking with rank(), we now use the percent_rank() window function. As with plain ranking, ordering is key to obtain the ranking percentages you want. select custno , case when percent_rank () over ( order by sum ( linetotal )) >= 0 . 8 then 'A' when percent_rank () over ( order by sum ( linetotal )) < 0 . 3 then 'C' else 'B' end as label from factSales group by custno order by custno ; Repeating the over () clause looks a bit clumsy, but it's just how the case operator works. The percent_rank() function is a bit difficult to grasp at first. The lowest ranking group is always 0%. The highest ranking group is always m/(n-1) % where n is the number of rows (observations) and m is the number of rows with a lower value for the column you want to rank on. (Hence, we always start with 0% as no rows will have a lower value than the lowest value.) Try the query below and change some data in order to get a good understanding of the percent_rank() function. Do not just change and run, but first predict what the result should be. If the result is conform your expectation, you've probably understood. If not, your mental model is wrong and you have to do some more thinking and experimenting. select id , percent_rank () over ( order by val ) [ % rank ] from ( values ( 1 , 1 ), ( 2 , 1 ), ( 3 , 2 ), ( 4 , 3 ), ( 5 , 3 ) ) T ( id , val ) order by id ;","title":"15. ABC labeling"},{"location":"demoqueries/#16-basic-statistical-measures","text":"What is the number, max, min, mean and standard deviation of the sales value per order? with cte as ( select sum ( linetotal ) ordval from factSales group by orderno ) select count ( * ) as n , min ( ordval ) as min , max ( ordval ) as max , avg ( ordval ) as mean , stdev ( ordval ) as stdev from cte ; Create a chart feeder for a histogram of sales values per order in Excel. Best to create a simple chart feeder and let Excel do the the heavy lifting of histogramming as binning is bit of a nuisance in SQL. select sum ( linetotal ) ordval from factSales group by orderno ;","title":"16. Basic statistical measures"},{"location":"demoqueries/#17-revenue-contribution","text":"Calculate the contribution to revenue (as percentage) of each product category in each region. Present as pivot with product categories on columns and region on rows. select regioncode , sum ( case when catcode = 'bio' then linetotal end ) as bio , sum ( case when catcode = 'lux' then linetotal end ) as lux , sum ( case when catcode = 'zuv' then linetotal end ) as zuv from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode ; Calculate the relative contribution to revenue (as percentage) of each product category in each region. Relative to what? To total regional revenue? To total product category revenue or to total overall revenue? In Excel pivot table terminology: as a % of Row Total, a % of Column Total or a % of Grand Total? We solve all three: -- percentage of regional revenue (% of row total) select regioncode , sum ( case when catcode = 'bio' then linetotal end ) / sum ( linetotal ) as bio , sum ( case when catcode = 'lux' then linetotal end ) / sum ( linetotal ) as lux , sum ( case when catcode = 'zuv' then linetotal end ) / sum ( linetotal ) as zuv from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode ; -- percentage of product category revenue (% of column total) select regioncode , sum ( case when catcode = 'bio' then linetotal end ) / ( select sum ( linetotal ) from dimProduct p join factSales s on s . prodno = p . prodno where catcode = 'bio' ) as bio , sum ( case when catcode = 'lux' then linetotal end ) / ( select sum ( linetotal ) from dimProduct p join factSales s on s . prodno = p . prodno where catcode = 'lux' ) as lux , sum ( case when catcode = 'zuv' then linetotal end ) / ( select sum ( linetotal ) from dimProduct p join factSales s on s . prodno = p . prodno where catcode = 'zuv' ) as bio from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode ; We can make this a bit less verbose with a common table expression: -- percentage of product category revenue (% of column total) with cte as ( select regioncode , catcode , sum ( linetotal ) as total from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode , catcode ) select regioncode , sum ( case when catcode = 'bio' then total end ) / ( select sum ( total ) from cte where catcode = 'bio' ) as bio , sum ( case when catcode = 'lux' then total end ) / ( select sum ( total ) from cte where catcode = 'lux' ) as lux , sum ( case when catcode = 'zuv' then total end ) / ( select sum ( total ) from cte where catcode = 'zuv' ) as zuv from cte co group by regioncode ; Finally the query to calculate the percentage of total revenue for each region/product category combination: -- percentage of overall revenue (% of grand total) select regioncode , sum ( case when catcode = 'bio' then linetotal end ) / ( sum ( sum ( linetotal )) over ()) as bio , sum ( case when catcode = 'lux' then linetotal end ) / ( sum ( sum ( linetotal )) over ()) as lux , sum ( case when catcode = 'zuv' then linetotal end ) / ( sum ( sum ( linetotal )) over ()) as zuv from dimCustomer c cross join dimProduct p left join factSales s on s . custno = c . custno and s . prodno = p . prodno group by regioncode ; We do not necessarily need a window function as denominator as a straightforward subquery will do as well: ... sum ( case when catcode = 'bio' then linetotal end ) / ( select sum ( linetotal ) from factSales ) as bio , ...","title":"17. Revenue contribution"},{"location":"exercisequeries/","text":"Exercise Queries \u00b6 Always validate your results by checking it against a joinThemAll table in Excel or a simple SQL check query! If you want to get inspiration to solve either of these exercise queries, here's a list of demo queries you could study to solve the exercise queries: Demo Queries Exercise Queries 1 1, 2 2 1, 2 3 4 4 9 5 12 6 6, 8, 11 7 12 8 14 9 11 10 11 12 13 14 15 1. Average order value \u00b6 What is the average order value per city in 2016? This is a warming up exercise. Hint: factSales has order line granularity. Do not calculate the average order line value! select city , sum ( linetotal ) / count ( distinct orderno ) as [ avg order value ] from dimCustomer c join factSales s on s . custno = c . custno where year ( orderdate ) = 2016 group by city ; 2. Average number of items sold (1) \u00b6 What is for each product for each year the average number of items sold in an order? select proddesc , year ( orderdate ) as year , sum ( quantity ) / count ( distinct orderno ) as [ avg # items sold ] from dimProduct p join factSales s on s . prodno = p . prodno group by proddesc , year ( orderdate ) ; 3. Average number of items sold (2) \u00b6 What is for each product for each month in 2016 the average number of items sold in an order? Order by month name, then by product description. Hint: you don't want alphabetic month name ordering. To get proper Jan - Dec ordering, you need to use the month number. select monthname as mnth , proddesc , sum ( quantity ) / count ( distinct orderno ) as [ avg # items sold ] from dimDate cross join dimProduct p left join factSales s on s . prodno = p . prodno where year ( orderdate ) = 2016 group by monthno , monthname , proddesc order by monthno , proddesc ; 4. Proportion of yearly revenue \u00b6 Calculate for each customer for each month in 2016 the proportion of yearly revenue. Your answer should look something like: name monthname monthly proportion Williams Jan 12.30 % Williams Feb 27.21 % Williams Mar 0.00 % ... ... ... Hint: in each line divide the monthly revenue by the yearly revenue for that specific customer. select name , monthname , format ( isnull ( sum ( linetotal ) / sum ( sum ( linetotal )) over ( partition by name ), 0 ), 'p' ) as [ monthly proportion ] from dimDate cross join dimCustomer c left join factSales s on orderdate = dat and s . custno = c . custno where year = 2016 group by name , monthno , monthname order by name , monthno ; 5. Year-over-year sales (1) \u00b6 Calculate for each salesrep the year-over-year total sales increase for all years. Hint: look at the YoY demo query and take into account that we don't want cumulative revenue. with cte as ( select salesrep , year , sum ( linetotal ) as total from dimDate cross join factSales group by salesrep , year ) select cur . salesrep , cur . year , ( cur . total - prev . total ) / prev . total as [ YoY Rev Increase % ] from cte as cur join cte as prev on cur . salesrep = prev . salesrep and prev . year = cur . year - 1 5. Year-over-year sales (2) \u00b6 Calculate monthly year-over-year sales increase (percentage, non cumulative) for each city for all years. A solution in the same fashion as previous solution would be: with cte as ( select city , year , monthNo , monthName , sum ( linetotal ) as total from dimDate cross join dimCustomer c left join factSales s on s . custno = c . custno and orderdate = dat group by city , year , monthNo , monthName ) select cur . city , cur . year , cur . monthName , ( cur . total - prev . total ) / prev . total as [ YoY Rev Increase % ] from cte as cur join cte as prev on cur . city = prev . city and prev . monthNo = cur . monthNo and prev . year = cur . year - 1 order by city , year , cur . monthNo A whole different soltion would be to make use of your knowledge of the available years in the database. Usually it is bad style to use your knowledge of specific data in a database, but we want to show you this solution anyway: with cte as ( select monthno , monthname , city , sum ( case year when 2016 then linetotal end ) as rev , sum ( case year when 2015 then linetotal end ) as revLY from dimDate cross join dimCustomer c left join factSales s on s . custno = c . custno and orderdate = dat where year in ( 2015 , 2016 ) group by monthno , monthname , city ) select city , monthno , monthname , city , rev , revLY , ( rev - revLY ) / revLY as [ YoY Rev Increase % ] from cte ; A better solution in the same direction of thinking would be to use the lag() window function: with cte as ( select year , monthno , monthname , city , isnull ( sum ( linetotal ), 0 ) as rev , lag ( sum ( linetotal )) over ( partition by city , monthno order by year ) as revLY from dimDate cross join dimCustomer c left join factSales s on s . custno = c . custno and orderdate = dat group by monthno , year , monthname , city ) select city , year , monthName , ( rev - revLY ) / revLY as [ % YoY rev increase ] from cte where year > ( select min ( year ( orderdate )) from factSales ) order by city , year , monthNo ; Note that in order to get rid of all NULL values from our first year we've added the guard year > (select min(year(orderdate)) from factSales) . 6. Days between orders \u00b6 What is for each customer the number of days between their last and last but one order? Hints: use the row_number() window function to rank orders based on their order date then select the most recent 2 (the most recent having the highest rank) First we solve a more general question: what are last and last but one order dates for each customer? We use the row_number() window function to tank each order line. Since factSales has order line granularity, you have to group on orderno. A tie breaker for order on the same date (e.g. orderno) is not necessary with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno from factSales group by orderno , custno , orderdate -- ! watch this: possibly more than 1 orderline per orderno! ) select custno , orderdate from cte where rno <= 2 ; Now it's easy to specialize to calculating the difference between both dates with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno from factSales group by orderno , custno , orderdate ) select custno , datediff ( d , min ( orderdate ), max ( orderdate )) as diff from cte where rno <= 2 group by custno ; A slightly different type of solution is to use a lead() in combination with row_number(). The lead() is used to calculate for each row (order) the difference in days with the immediately preceding order. with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno , datediff ( d , lead ( orderdate ) over ( partition by custno order by orderdate desc ), orderdate ) as diff from factSales group by orderno , custno , orderdate ) select custno , diff from cte where rno = 1 ; Note: though a bit more difficult to grasp, we can also solve this using the cross apply table operator: select c . custno , datediff ( d , min ( orderdate ), max ( orderdate )) as diff from dimCustomer c cross apply ( select top ( 2 ) custno , orderdate from factSales s where s . custno = c . custno group by orderno , custno , orderdate -- factSales has order line granularity! order by orderdate desc , orderno ) t group by c . custno ; Finally, a more traditional (but properly working) approach would be to use a correlated subquery. I suspect this query to be less performant than the cross apply solution as in this solution the factSales will be re-queried for each line in factSales, whereas in the cross apply solution it will be queried for each customer select custno , datediff ( d , min ( orderdate ), max ( orderdate )) as diff from factSales s where orderno in ( select top ( 2 ) orderno from factSales si where si . custno = s . custno group by orderno , orderdate order by orderdate desc ) group by custno ; 7. Average time between orders \u00b6 What is for each customer the average time lag between 2 orders of the 5 most recent orders of this customer? So you have to collect the 5 most recent orders per customer, calculate the 4 time lags between subsequent orders and then calculate the average of these 4 time lags. Hints: use the lead() window function to look something up in a successor row use the avg() function to calculate an average check/test your results with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc , orderno ) as rno , datediff ( d , lead ( orderdate ) over ( partition by custno order by orderdate desc ), orderdate ) as tlag from factSales group by orderno , custno , orderdate ) select custno , avg ( convert ( float , tlag )) as [ avg time lag ] from cte where rno <= 4 group by custno ; Note that we calculate the following average expression: (d2 - d1) + (d3 - d2) + (d4 - d3) + (d5 - d4)/4 which can be simplified to (d5-d1)/4. In SQL: with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno from factSales group by orderno , custno , orderdate ) select custno , datediff ( d , min ( orderdate ), max ( orderdate )) as diff from cte where rno in ( 1 , 5 ) group by custno ; The main difference with the first solution is that if you don't have at least 5 dates for different orders, the latter gives 0 (min and max are the same) whereas the first solution gives the average of all dates it found, even if there were less than 5. You can, however, adapt the second solution to get the same behavior: with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno from factSales group by orderno , custno , orderdate ) select custno , convert ( float , datediff ( d , min ( orderdate ), max ( orderdate ))) / ( count ( * ) - 1 ) as diff from cte where rno <= 5 group by custno ; 8. Cumulative revenue \u00b6 Calculate total revenue and total cumulative revenue for each year, for each month select year , monthname , sum ( linetotal ) as rev , sum ( sum ( linetotal )) over ( order by monthno ) as cumrev from dimDate d join factSales s on orderdate = dat group by year , monthname , monthno ; Visualize the result in a combo chart with years on slicers 9. Cumulative revenue pivoted \u00b6 Calculate cumulative revenue for each year, each month, each regioncode and each product category. Present in pivot format with product category on columns select year , monthno , monthname , regioncode , sum ( sum ( case when catcode = 'bio' then linetotal end )) over ( partition by year , regioncode order by monthno ) as Bio , sum ( sum ( case when catcode = 'lux' then linetotal end )) over ( partition by year , regioncode order by monthno ) as Lux , sum ( sum ( case when catcode = 'zuv' then linetotal end )) over ( partition by year , regioncode order by monthno ) as Zuv from dimDate cross join dimCustomer c cross join dimProduct p left join factSales s on orderdate = dat and s . custno = c . custno and s . prodno = p . prodno group by year , monthno , monthname , regioncode ; Visualize in a stacked bar chart (product categories as series), with months on x-axis and years and region code on slicers. 10. Percentage of total \u00b6 Calculate the monthly revenue in 2016 of each product category as a percentage of total revenue for that product category in that year. Hint: the demo query calculates an Excel equivalent of percentage of row total. Here you have to calculate the Excel percentage of column total equivalent. select monthname , catcode , sum ( linetotal ) / ( sum ( sum ( linetotal )) over ( partition by catcode )) from dimDate cross join dimProduct p join factSales s on s . prodno = p . prodno and orderdate = dat where year ( orderdate ) = 2016 group by monthno , monthname , catcode ; If you want to present in pivot format with product categories on columns, it is easiest to do so with previous query as a common table expression: with cte as ( select monthno , monthname , catcode , sum ( linetotal ) / ( sum ( sum ( linetotal )) over ( partition by catcode )) as [ % rev ] from dimDate cross join dimProduct p join factSales s on s . prodno = p . prodno and orderdate = dat where year ( orderdate ) = 2016 group by monthno , monthname , catcode ) select monthname , sum ( case when catcode = 'bio' then [ % rev ] end ) as bio , sum ( case when catcode = 'lux' then [ % rev ] end ) as lux , sum ( case when catcode = 'zuv' then [ % rev ] end ) as zuv from cte group by monthno , monthname , monthname order by monthno ; Although summing percentages from the cte may look ridiculous, it is save here, because you will only sum a single value for a particular month/product category combination. So you might just as well have used a max() or a min() in the query above. 11. Best spending customers \u00b6 Which customers in each region spent most in 2016? with cte as ( select regioncode , custno , name , sum ( linetotal ) as totalSpent , row_number () over ( partition by regioncode order by sum ( linetotal ) desc ) as rno from dimCustomer c join factSales s on s . custno = c . custno group by regioncode , c . custno , name ) select regioncode , c . custno , name , totalSpent from cte where rno = 1 ; 12. Periodical growth \u00b6 What is for each product category the yearly growth (percentage) of quantity sold in 2015 and 2016? with cte as ( select year ( orderdate ) as yr , catcode , sum ( linetotal ) as totSales , lag ( sum ( linetotal )) over ( partition by catcode order by year ( orderdate )) as totSalesLY from dimProduct p join factSales s on s . prodno = p . prodno group by year ( orderdate ), catcode ) select yr , catcode , ( totSales - totSalesLY ) / totSalesLY from cte where totSalesLY is not null ; 13. Weekend and weekday buyers \u00b6 Weekend buyers place at least 40% of their orders in weekends. Which customers can be labeled as weekend buyers? Hints: look at query 11 from the demo series use a having clause if you have a condition on a group result keep in mind that factSales has order line granularity with cte as ( -- select all unique orders with their customer and order date select distinct custno , orderno , orderdate from factSales ) select custno from cte group by custno having avg ( case when datepart ( dw , orderdate ) in ( 1 , 7 ) then 1 . 0 else 0 . 0 end ) >= 0 . 4 ; Well, that's a funny looking having clause ... It is a pattern you can often use when you have to produce a percentage of countable events, in this case order transactions in the weekend as a percentage of all order transactions. In the case we label each positive transaction with a 1 and each negative transaction with a 0. Then we calculate the average of this column of 1-2 and 0-s. That average is exactly the percentage of 1-s or the percentage of positive events. 14. Maximum lag time \u00b6 What is for each customer the longest period (in days) between two consecutive orders in January 2016? Note that you can only calculate this for customers that placed at least 2 orders in 2016. with cte as ( select custno , datediff ( d , lead ( orderdate ) over ( partition by custno order by orderdate desc ), orderdate ) as diff from factSales where year ( orderdate ) = 2016 and month ( orderdate ) = 1 group by custno , orderno , orderdate ) select custno , max ( diff ) as maxdiff from cte where diff is not null group by custno ; 15. Orders per day of week \u00b6 Present for each customer their number of orders per day of week in 2016 in an Excel column chart Hint: look at queries 11 and 12. First create a result without pivoting: select custno , datename ( dw , orderdate ) as dy , count ( distinct orderno ) as [ # orders ] from factSales where year ( orderdate ) = 2016 group by custno , datename ( dw , orderdate ) ; Then pivot. First we pivot using the case operator: select custno , sum ( case datepart ( dw , orderdate ) when 1 then 1 else 0 end ) as Sunday , sum ( case datepart ( dw , orderdate ) when 2 then 1 else 0 end ) as Monday , sum ( case datepart ( dw , orderdate ) when 3 then 1 else 0 end ) as Tuesday , sum ( case datepart ( dw , orderdate ) when 4 then 1 else 0 end ) as Wednesday , sum ( case datepart ( dw , orderdate ) when 5 then 1 else 0 end ) as Thursday , sum ( case datepart ( dw , orderdate ) when 6 then 1 else 0 end ) as Friday , sum ( case datepart ( dw , orderdate ) when 7 then 1 else 0 end ) as Saturday from factSales where year ( orderdate ) = 2016 group by custno ; Looks ok, right? It isn't, however. In the pivoted solution we are counting order lines instead of unique orders. We've lost the distinct feature from the first non pivoted solution. We solve by first filtering the unique custno, orderno, orderdate combination in 2016 in the factSales table: with cte as ( select distinct custno , orderno , orderdate from factSales where year ( orderdate ) = 2016 ) select custno , sum ( case datepart ( dw , orderdate ) when 1 then 1 else 0 end ) as Sunday , sum ( case datepart ( dw , orderdate ) when 2 then 1 else 0 end ) as Monday , sum ( case datepart ( dw , orderdate ) when 3 then 1 else 0 end ) as Tuesday , sum ( case datepart ( dw , orderdate ) when 4 then 1 else 0 end ) as Wednesday , sum ( case datepart ( dw , orderdate ) when 5 then 1 else 0 end ) as Thursday , sum ( case datepart ( dw , orderdate ) when 6 then 1 else 0 end ) as Friday , sum ( case datepart ( dw , orderdate ) when 7 then 1 else 0 end ) as Saturday from cte group by custno ; If we join with dimDate, we can make use of the pre-calculated days: with cte as ( select distinct custno , orderno , dayInWeek from dimDate join factSales on orderdate = dat where year ( orderdate ) = 2016 ) select custno , sum ( case dayInWeek when 1 then 1 else 0 end ) as Sunday , sum ( case dayInWeek when 2 then 1 else 0 end ) as Monday , sum ( case dayInWeek when 3 then 1 else 0 end ) as Tuesday , sum ( case dayInWeek when 4 then 1 else 0 end ) as Wednesday , sum ( case dayInWeek when 5 then 1 else 0 end ) as Thursday , sum ( case dayInWeek when 6 then 1 else 0 end ) as Friday , sum ( case dayInWeek when 7 then 1 else 0 end ) as Saturday from cte group by custno ; There is no need to left join here, as the explicit weekday column calculation already takes care of that. Alternatively we can use T-SQL's pivot table operator: select custno , Sunday , Monday , Tuesday , Wednesday , Thursday , Friday , Saturday from ( select custno , datename ( dw , orderdate ) as dy , count ( distinct orderno ) as [ # orders ] from factSales where year ( orderdate ) = 2016 group by custno , datename ( dw , orderdate ) ) as T1 pivot ( sum ([ # orders ]) for dy in ( Sunday , Monday , Tuesday , Wednesday , Thursday , Friday , Saturday ) ) asT2 ; Note that Excel will handle the NULLs properly. 16. Transactions vs revenue \u00b6 Create a (regular) chart in Excel comparing monthly sales transactions with monthly revenue in 2016. select monthno , monthname , count ( distinct orderno ) as [ # tx ], sum ( linetotal ) as rev from dimDate left join factSales on orderdate = dat where year = 2016 group by monthno , monthname order by monthno ; 17. Transactions per day of week \u00b6 Present for each customer their number of orders per day of week in January 2016. Being lazy and copying a proven solution for a new problem is often a good thing. But this solution needs some more. -- inferior solution select custno , sum ( case datepart ( dw , orderdate ) when 1 then 1 else 0 end ) as Sunday , sum ( case datepart ( dw , orderdate ) when 2 then 1 else 0 end ) as Monday , sum ( case datepart ( dw , orderdate ) when 3 then 1 else 0 end ) as Tuesday , sum ( case datepart ( dw , orderdate ) when 4 then 1 else 0 end ) as Wednesday , sum ( case datepart ( dw , orderdate ) when 5 then 1 else 0 end ) as Thursday , sum ( case datepart ( dw , orderdate ) when 6 then 1 else 0 end ) as Friday , sum ( case datepart ( dw , orderdate ) when 7 then 1 else 0 end ) as Saturday from factSales where orderdate between '2016-01-01' and '2016-01-31' group by custno ; Oops, we lost track of a number of customers now the time frame is a lot smaller. Let's fix that: select c . custno , sum ( case datepart ( dw , orderdate ) when 1 then 1 else 0 end ) as Sunday , sum ( case datepart ( dw , orderdate ) when 2 then 1 else 0 end ) as Monday , sum ( case datepart ( dw , orderdate ) when 3 then 1 else 0 end ) as Tuesday , sum ( case datepart ( dw , orderdate ) when 4 then 1 else 0 end ) as Wednesday , sum ( case datepart ( dw , orderdate ) when 5 then 1 else 0 end ) as Thursday , sum ( case datepart ( dw , orderdate ) when 6 then 1 else 0 end ) as Friday , sum ( case datepart ( dw , orderdate ) when 7 then 1 else 0 end ) as Saturday from dimCustomer c left join factSales s on s . custno = c . custno and orderdate between '2016-01-01' and '2016-01-31' group by c . custno ; Note that the order date condition should not be in the where clause but in the on clause in order to really get all customers. There is no need to outer join dimDate as well, because we explicitly add columns for each weekday. In the result you can see that there haven't been any sales on Mondays, Tuesdays and Thursdays. 18. Weekday ranking \u00b6 Give for each month in 2016 a weekday ranking with the weekday with the most transactions on top. Present in pivot format with weekdays on rows and month names on columns. Show results in an Excel chart. Hint: look at query 13 from the demo series. select datepart ( dw , dat ) as dyno , datename ( dw , dat ) dy , rank () over ( order by count ( distinct case monthno when 1 then orderno end ) desc ) as Jan , rank () over ( order by count ( distinct case monthno when 2 then orderno end ) desc ) as Feb , rank () over ( order by count ( distinct case monthno when 3 then orderno end ) desc ) as Mar , rank () over ( order by count ( distinct case monthno when 4 then orderno end ) desc ) as Apr , rank () over ( order by count ( distinct case monthno when 5 then orderno end ) desc ) as May , rank () over ( order by count ( distinct case monthno when 6 then orderno end ) desc ) as Jun , rank () over ( order by count ( distinct case monthno when 7 then orderno end ) desc ) as Jul , rank () over ( order by count ( distinct case monthno when 8 then orderno end ) desc ) as Aug , rank () over ( order by count ( distinct case monthno when 9 then orderno end ) desc ) as Sep , rank () over ( order by count ( distinct case monthno when 10 then orderno end ) desc ) as Oct , rank () over ( order by count ( distinct case monthno when 11 then orderno end ) desc ) as Nov , rank () over ( order by count ( distinct case monthno when 12 then orderno end ) desc ) as Dec from dimDate left join factSales on orderdate = dat where year = 2016 group by datename ( dw , dat ), datepart ( dw , dat ) order by datepart ( dw , dat ) ; Tsss, that's an odd looking solution. And not really intuitive either. And yet the only thing we did was substitute the count(case ...) for the count(orderdate) in previous solution. If I had to solve this query without having solved the previous one first, I don't think I would have succeeded. That's why it is a very practical and good strategy to always try to solve a simpler version of your query to get some sense of structure and solution direction. It is debatable whether this result set format is the most convenient to base visuals on in charts. Perhaps the unpivoted version below is more suited in Excel: select monthno , monthname , datepart ( dw , dat ) as dyno , datename ( dw , dat ) dy , rank () over ( partition by monthno order by count ( distinct orderno ) desc ) as rnk from dimDate left join factSales on orderdate = dat where year = 2016 group by monthno , monthname , datename ( dw , dat ), datepart ( dw , dat ) order by monthno , datepart ( dw , dat ) ; Because dimDate has additional columns for month number and month name, we can use them in this query. However, there are no additional columns for weekday and weekday number, so we have to calculate them. 19. ABC labeling \u00b6 Calculate ABC labeling for all product categories. Hint: look at query 15 from the demo series. select catcode , case when percent_rank () over ( order by sum ( linetotal ) desc ) <= 0 . 2 then 'A' when percent_rank () over ( order by sum ( linetotal ) desc ) >= 0 . 7 then 'C' else 'B' end as label from dimProduct p join factSales s on p . prodno = s . prodno group by catcode order by catcode ;","title":"Exercise Queries"},{"location":"exercisequeries/#exercise-queries","text":"Always validate your results by checking it against a joinThemAll table in Excel or a simple SQL check query! If you want to get inspiration to solve either of these exercise queries, here's a list of demo queries you could study to solve the exercise queries: Demo Queries Exercise Queries 1 1, 2 2 1, 2 3 4 4 9 5 12 6 6, 8, 11 7 12 8 14 9 11 10 11 12 13 14 15","title":"Exercise Queries"},{"location":"exercisequeries/#1-average-order-value","text":"What is the average order value per city in 2016? This is a warming up exercise. Hint: factSales has order line granularity. Do not calculate the average order line value! select city , sum ( linetotal ) / count ( distinct orderno ) as [ avg order value ] from dimCustomer c join factSales s on s . custno = c . custno where year ( orderdate ) = 2016 group by city ;","title":"1. Average order value"},{"location":"exercisequeries/#2-average-number-of-items-sold-1","text":"What is for each product for each year the average number of items sold in an order? select proddesc , year ( orderdate ) as year , sum ( quantity ) / count ( distinct orderno ) as [ avg # items sold ] from dimProduct p join factSales s on s . prodno = p . prodno group by proddesc , year ( orderdate ) ;","title":"2. Average number of items sold (1)"},{"location":"exercisequeries/#3-average-number-of-items-sold-2","text":"What is for each product for each month in 2016 the average number of items sold in an order? Order by month name, then by product description. Hint: you don't want alphabetic month name ordering. To get proper Jan - Dec ordering, you need to use the month number. select monthname as mnth , proddesc , sum ( quantity ) / count ( distinct orderno ) as [ avg # items sold ] from dimDate cross join dimProduct p left join factSales s on s . prodno = p . prodno where year ( orderdate ) = 2016 group by monthno , monthname , proddesc order by monthno , proddesc ;","title":"3. Average number of items sold (2)"},{"location":"exercisequeries/#4-proportion-of-yearly-revenue","text":"Calculate for each customer for each month in 2016 the proportion of yearly revenue. Your answer should look something like: name monthname monthly proportion Williams Jan 12.30 % Williams Feb 27.21 % Williams Mar 0.00 % ... ... ... Hint: in each line divide the monthly revenue by the yearly revenue for that specific customer. select name , monthname , format ( isnull ( sum ( linetotal ) / sum ( sum ( linetotal )) over ( partition by name ), 0 ), 'p' ) as [ monthly proportion ] from dimDate cross join dimCustomer c left join factSales s on orderdate = dat and s . custno = c . custno where year = 2016 group by name , monthno , monthname order by name , monthno ;","title":"4. Proportion of yearly revenue"},{"location":"exercisequeries/#5-year-over-year-sales-1","text":"Calculate for each salesrep the year-over-year total sales increase for all years. Hint: look at the YoY demo query and take into account that we don't want cumulative revenue. with cte as ( select salesrep , year , sum ( linetotal ) as total from dimDate cross join factSales group by salesrep , year ) select cur . salesrep , cur . year , ( cur . total - prev . total ) / prev . total as [ YoY Rev Increase % ] from cte as cur join cte as prev on cur . salesrep = prev . salesrep and prev . year = cur . year - 1","title":"5. Year-over-year sales (1)"},{"location":"exercisequeries/#5-year-over-year-sales-2","text":"Calculate monthly year-over-year sales increase (percentage, non cumulative) for each city for all years. A solution in the same fashion as previous solution would be: with cte as ( select city , year , monthNo , monthName , sum ( linetotal ) as total from dimDate cross join dimCustomer c left join factSales s on s . custno = c . custno and orderdate = dat group by city , year , monthNo , monthName ) select cur . city , cur . year , cur . monthName , ( cur . total - prev . total ) / prev . total as [ YoY Rev Increase % ] from cte as cur join cte as prev on cur . city = prev . city and prev . monthNo = cur . monthNo and prev . year = cur . year - 1 order by city , year , cur . monthNo A whole different soltion would be to make use of your knowledge of the available years in the database. Usually it is bad style to use your knowledge of specific data in a database, but we want to show you this solution anyway: with cte as ( select monthno , monthname , city , sum ( case year when 2016 then linetotal end ) as rev , sum ( case year when 2015 then linetotal end ) as revLY from dimDate cross join dimCustomer c left join factSales s on s . custno = c . custno and orderdate = dat where year in ( 2015 , 2016 ) group by monthno , monthname , city ) select city , monthno , monthname , city , rev , revLY , ( rev - revLY ) / revLY as [ YoY Rev Increase % ] from cte ; A better solution in the same direction of thinking would be to use the lag() window function: with cte as ( select year , monthno , monthname , city , isnull ( sum ( linetotal ), 0 ) as rev , lag ( sum ( linetotal )) over ( partition by city , monthno order by year ) as revLY from dimDate cross join dimCustomer c left join factSales s on s . custno = c . custno and orderdate = dat group by monthno , year , monthname , city ) select city , year , monthName , ( rev - revLY ) / revLY as [ % YoY rev increase ] from cte where year > ( select min ( year ( orderdate )) from factSales ) order by city , year , monthNo ; Note that in order to get rid of all NULL values from our first year we've added the guard year > (select min(year(orderdate)) from factSales) .","title":"5. Year-over-year sales (2)"},{"location":"exercisequeries/#6-days-between-orders","text":"What is for each customer the number of days between their last and last but one order? Hints: use the row_number() window function to rank orders based on their order date then select the most recent 2 (the most recent having the highest rank) First we solve a more general question: what are last and last but one order dates for each customer? We use the row_number() window function to tank each order line. Since factSales has order line granularity, you have to group on orderno. A tie breaker for order on the same date (e.g. orderno) is not necessary with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno from factSales group by orderno , custno , orderdate -- ! watch this: possibly more than 1 orderline per orderno! ) select custno , orderdate from cte where rno <= 2 ; Now it's easy to specialize to calculating the difference between both dates with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno from factSales group by orderno , custno , orderdate ) select custno , datediff ( d , min ( orderdate ), max ( orderdate )) as diff from cte where rno <= 2 group by custno ; A slightly different type of solution is to use a lead() in combination with row_number(). The lead() is used to calculate for each row (order) the difference in days with the immediately preceding order. with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno , datediff ( d , lead ( orderdate ) over ( partition by custno order by orderdate desc ), orderdate ) as diff from factSales group by orderno , custno , orderdate ) select custno , diff from cte where rno = 1 ; Note: though a bit more difficult to grasp, we can also solve this using the cross apply table operator: select c . custno , datediff ( d , min ( orderdate ), max ( orderdate )) as diff from dimCustomer c cross apply ( select top ( 2 ) custno , orderdate from factSales s where s . custno = c . custno group by orderno , custno , orderdate -- factSales has order line granularity! order by orderdate desc , orderno ) t group by c . custno ; Finally, a more traditional (but properly working) approach would be to use a correlated subquery. I suspect this query to be less performant than the cross apply solution as in this solution the factSales will be re-queried for each line in factSales, whereas in the cross apply solution it will be queried for each customer select custno , datediff ( d , min ( orderdate ), max ( orderdate )) as diff from factSales s where orderno in ( select top ( 2 ) orderno from factSales si where si . custno = s . custno group by orderno , orderdate order by orderdate desc ) group by custno ;","title":"6. Days between orders"},{"location":"exercisequeries/#7-average-time-between-orders","text":"What is for each customer the average time lag between 2 orders of the 5 most recent orders of this customer? So you have to collect the 5 most recent orders per customer, calculate the 4 time lags between subsequent orders and then calculate the average of these 4 time lags. Hints: use the lead() window function to look something up in a successor row use the avg() function to calculate an average check/test your results with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc , orderno ) as rno , datediff ( d , lead ( orderdate ) over ( partition by custno order by orderdate desc ), orderdate ) as tlag from factSales group by orderno , custno , orderdate ) select custno , avg ( convert ( float , tlag )) as [ avg time lag ] from cte where rno <= 4 group by custno ; Note that we calculate the following average expression: (d2 - d1) + (d3 - d2) + (d4 - d3) + (d5 - d4)/4 which can be simplified to (d5-d1)/4. In SQL: with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno from factSales group by orderno , custno , orderdate ) select custno , datediff ( d , min ( orderdate ), max ( orderdate )) as diff from cte where rno in ( 1 , 5 ) group by custno ; The main difference with the first solution is that if you don't have at least 5 dates for different orders, the latter gives 0 (min and max are the same) whereas the first solution gives the average of all dates it found, even if there were less than 5. You can, however, adapt the second solution to get the same behavior: with cte as ( select custno , orderdate , row_number () over ( partition by custno order by orderdate desc ) as rno from factSales group by orderno , custno , orderdate ) select custno , convert ( float , datediff ( d , min ( orderdate ), max ( orderdate ))) / ( count ( * ) - 1 ) as diff from cte where rno <= 5 group by custno ;","title":"7. Average time between orders"},{"location":"exercisequeries/#8-cumulative-revenue","text":"Calculate total revenue and total cumulative revenue for each year, for each month select year , monthname , sum ( linetotal ) as rev , sum ( sum ( linetotal )) over ( order by monthno ) as cumrev from dimDate d join factSales s on orderdate = dat group by year , monthname , monthno ; Visualize the result in a combo chart with years on slicers","title":"8. Cumulative revenue"},{"location":"exercisequeries/#9-cumulative-revenue-pivoted","text":"Calculate cumulative revenue for each year, each month, each regioncode and each product category. Present in pivot format with product category on columns select year , monthno , monthname , regioncode , sum ( sum ( case when catcode = 'bio' then linetotal end )) over ( partition by year , regioncode order by monthno ) as Bio , sum ( sum ( case when catcode = 'lux' then linetotal end )) over ( partition by year , regioncode order by monthno ) as Lux , sum ( sum ( case when catcode = 'zuv' then linetotal end )) over ( partition by year , regioncode order by monthno ) as Zuv from dimDate cross join dimCustomer c cross join dimProduct p left join factSales s on orderdate = dat and s . custno = c . custno and s . prodno = p . prodno group by year , monthno , monthname , regioncode ; Visualize in a stacked bar chart (product categories as series), with months on x-axis and years and region code on slicers.","title":"9. Cumulative revenue pivoted"},{"location":"exercisequeries/#10-percentage-of-total","text":"Calculate the monthly revenue in 2016 of each product category as a percentage of total revenue for that product category in that year. Hint: the demo query calculates an Excel equivalent of percentage of row total. Here you have to calculate the Excel percentage of column total equivalent. select monthname , catcode , sum ( linetotal ) / ( sum ( sum ( linetotal )) over ( partition by catcode )) from dimDate cross join dimProduct p join factSales s on s . prodno = p . prodno and orderdate = dat where year ( orderdate ) = 2016 group by monthno , monthname , catcode ; If you want to present in pivot format with product categories on columns, it is easiest to do so with previous query as a common table expression: with cte as ( select monthno , monthname , catcode , sum ( linetotal ) / ( sum ( sum ( linetotal )) over ( partition by catcode )) as [ % rev ] from dimDate cross join dimProduct p join factSales s on s . prodno = p . prodno and orderdate = dat where year ( orderdate ) = 2016 group by monthno , monthname , catcode ) select monthname , sum ( case when catcode = 'bio' then [ % rev ] end ) as bio , sum ( case when catcode = 'lux' then [ % rev ] end ) as lux , sum ( case when catcode = 'zuv' then [ % rev ] end ) as zuv from cte group by monthno , monthname , monthname order by monthno ; Although summing percentages from the cte may look ridiculous, it is save here, because you will only sum a single value for a particular month/product category combination. So you might just as well have used a max() or a min() in the query above.","title":"10. Percentage of total"},{"location":"exercisequeries/#11-best-spending-customers","text":"Which customers in each region spent most in 2016? with cte as ( select regioncode , custno , name , sum ( linetotal ) as totalSpent , row_number () over ( partition by regioncode order by sum ( linetotal ) desc ) as rno from dimCustomer c join factSales s on s . custno = c . custno group by regioncode , c . custno , name ) select regioncode , c . custno , name , totalSpent from cte where rno = 1 ;","title":"11. Best spending customers"},{"location":"exercisequeries/#12-periodical-growth","text":"What is for each product category the yearly growth (percentage) of quantity sold in 2015 and 2016? with cte as ( select year ( orderdate ) as yr , catcode , sum ( linetotal ) as totSales , lag ( sum ( linetotal )) over ( partition by catcode order by year ( orderdate )) as totSalesLY from dimProduct p join factSales s on s . prodno = p . prodno group by year ( orderdate ), catcode ) select yr , catcode , ( totSales - totSalesLY ) / totSalesLY from cte where totSalesLY is not null ;","title":"12. Periodical growth"},{"location":"exercisequeries/#13-weekend-and-weekday-buyers","text":"Weekend buyers place at least 40% of their orders in weekends. Which customers can be labeled as weekend buyers? Hints: look at query 11 from the demo series use a having clause if you have a condition on a group result keep in mind that factSales has order line granularity with cte as ( -- select all unique orders with their customer and order date select distinct custno , orderno , orderdate from factSales ) select custno from cte group by custno having avg ( case when datepart ( dw , orderdate ) in ( 1 , 7 ) then 1 . 0 else 0 . 0 end ) >= 0 . 4 ; Well, that's a funny looking having clause ... It is a pattern you can often use when you have to produce a percentage of countable events, in this case order transactions in the weekend as a percentage of all order transactions. In the case we label each positive transaction with a 1 and each negative transaction with a 0. Then we calculate the average of this column of 1-2 and 0-s. That average is exactly the percentage of 1-s or the percentage of positive events.","title":"13. Weekend and weekday buyers"},{"location":"exercisequeries/#14-maximum-lag-time","text":"What is for each customer the longest period (in days) between two consecutive orders in January 2016? Note that you can only calculate this for customers that placed at least 2 orders in 2016. with cte as ( select custno , datediff ( d , lead ( orderdate ) over ( partition by custno order by orderdate desc ), orderdate ) as diff from factSales where year ( orderdate ) = 2016 and month ( orderdate ) = 1 group by custno , orderno , orderdate ) select custno , max ( diff ) as maxdiff from cte where diff is not null group by custno ;","title":"14. Maximum lag time"},{"location":"exercisequeries/#15-orders-per-day-of-week","text":"Present for each customer their number of orders per day of week in 2016 in an Excel column chart Hint: look at queries 11 and 12. First create a result without pivoting: select custno , datename ( dw , orderdate ) as dy , count ( distinct orderno ) as [ # orders ] from factSales where year ( orderdate ) = 2016 group by custno , datename ( dw , orderdate ) ; Then pivot. First we pivot using the case operator: select custno , sum ( case datepart ( dw , orderdate ) when 1 then 1 else 0 end ) as Sunday , sum ( case datepart ( dw , orderdate ) when 2 then 1 else 0 end ) as Monday , sum ( case datepart ( dw , orderdate ) when 3 then 1 else 0 end ) as Tuesday , sum ( case datepart ( dw , orderdate ) when 4 then 1 else 0 end ) as Wednesday , sum ( case datepart ( dw , orderdate ) when 5 then 1 else 0 end ) as Thursday , sum ( case datepart ( dw , orderdate ) when 6 then 1 else 0 end ) as Friday , sum ( case datepart ( dw , orderdate ) when 7 then 1 else 0 end ) as Saturday from factSales where year ( orderdate ) = 2016 group by custno ; Looks ok, right? It isn't, however. In the pivoted solution we are counting order lines instead of unique orders. We've lost the distinct feature from the first non pivoted solution. We solve by first filtering the unique custno, orderno, orderdate combination in 2016 in the factSales table: with cte as ( select distinct custno , orderno , orderdate from factSales where year ( orderdate ) = 2016 ) select custno , sum ( case datepart ( dw , orderdate ) when 1 then 1 else 0 end ) as Sunday , sum ( case datepart ( dw , orderdate ) when 2 then 1 else 0 end ) as Monday , sum ( case datepart ( dw , orderdate ) when 3 then 1 else 0 end ) as Tuesday , sum ( case datepart ( dw , orderdate ) when 4 then 1 else 0 end ) as Wednesday , sum ( case datepart ( dw , orderdate ) when 5 then 1 else 0 end ) as Thursday , sum ( case datepart ( dw , orderdate ) when 6 then 1 else 0 end ) as Friday , sum ( case datepart ( dw , orderdate ) when 7 then 1 else 0 end ) as Saturday from cte group by custno ; If we join with dimDate, we can make use of the pre-calculated days: with cte as ( select distinct custno , orderno , dayInWeek from dimDate join factSales on orderdate = dat where year ( orderdate ) = 2016 ) select custno , sum ( case dayInWeek when 1 then 1 else 0 end ) as Sunday , sum ( case dayInWeek when 2 then 1 else 0 end ) as Monday , sum ( case dayInWeek when 3 then 1 else 0 end ) as Tuesday , sum ( case dayInWeek when 4 then 1 else 0 end ) as Wednesday , sum ( case dayInWeek when 5 then 1 else 0 end ) as Thursday , sum ( case dayInWeek when 6 then 1 else 0 end ) as Friday , sum ( case dayInWeek when 7 then 1 else 0 end ) as Saturday from cte group by custno ; There is no need to left join here, as the explicit weekday column calculation already takes care of that. Alternatively we can use T-SQL's pivot table operator: select custno , Sunday , Monday , Tuesday , Wednesday , Thursday , Friday , Saturday from ( select custno , datename ( dw , orderdate ) as dy , count ( distinct orderno ) as [ # orders ] from factSales where year ( orderdate ) = 2016 group by custno , datename ( dw , orderdate ) ) as T1 pivot ( sum ([ # orders ]) for dy in ( Sunday , Monday , Tuesday , Wednesday , Thursday , Friday , Saturday ) ) asT2 ; Note that Excel will handle the NULLs properly.","title":"15. Orders per day of week"},{"location":"exercisequeries/#16-transactions-vs-revenue","text":"Create a (regular) chart in Excel comparing monthly sales transactions with monthly revenue in 2016. select monthno , monthname , count ( distinct orderno ) as [ # tx ], sum ( linetotal ) as rev from dimDate left join factSales on orderdate = dat where year = 2016 group by monthno , monthname order by monthno ;","title":"16. Transactions vs revenue"},{"location":"exercisequeries/#17-transactions-per-day-of-week","text":"Present for each customer their number of orders per day of week in January 2016. Being lazy and copying a proven solution for a new problem is often a good thing. But this solution needs some more. -- inferior solution select custno , sum ( case datepart ( dw , orderdate ) when 1 then 1 else 0 end ) as Sunday , sum ( case datepart ( dw , orderdate ) when 2 then 1 else 0 end ) as Monday , sum ( case datepart ( dw , orderdate ) when 3 then 1 else 0 end ) as Tuesday , sum ( case datepart ( dw , orderdate ) when 4 then 1 else 0 end ) as Wednesday , sum ( case datepart ( dw , orderdate ) when 5 then 1 else 0 end ) as Thursday , sum ( case datepart ( dw , orderdate ) when 6 then 1 else 0 end ) as Friday , sum ( case datepart ( dw , orderdate ) when 7 then 1 else 0 end ) as Saturday from factSales where orderdate between '2016-01-01' and '2016-01-31' group by custno ; Oops, we lost track of a number of customers now the time frame is a lot smaller. Let's fix that: select c . custno , sum ( case datepart ( dw , orderdate ) when 1 then 1 else 0 end ) as Sunday , sum ( case datepart ( dw , orderdate ) when 2 then 1 else 0 end ) as Monday , sum ( case datepart ( dw , orderdate ) when 3 then 1 else 0 end ) as Tuesday , sum ( case datepart ( dw , orderdate ) when 4 then 1 else 0 end ) as Wednesday , sum ( case datepart ( dw , orderdate ) when 5 then 1 else 0 end ) as Thursday , sum ( case datepart ( dw , orderdate ) when 6 then 1 else 0 end ) as Friday , sum ( case datepart ( dw , orderdate ) when 7 then 1 else 0 end ) as Saturday from dimCustomer c left join factSales s on s . custno = c . custno and orderdate between '2016-01-01' and '2016-01-31' group by c . custno ; Note that the order date condition should not be in the where clause but in the on clause in order to really get all customers. There is no need to outer join dimDate as well, because we explicitly add columns for each weekday. In the result you can see that there haven't been any sales on Mondays, Tuesdays and Thursdays.","title":"17. Transactions per day of week"},{"location":"exercisequeries/#18-weekday-ranking","text":"Give for each month in 2016 a weekday ranking with the weekday with the most transactions on top. Present in pivot format with weekdays on rows and month names on columns. Show results in an Excel chart. Hint: look at query 13 from the demo series. select datepart ( dw , dat ) as dyno , datename ( dw , dat ) dy , rank () over ( order by count ( distinct case monthno when 1 then orderno end ) desc ) as Jan , rank () over ( order by count ( distinct case monthno when 2 then orderno end ) desc ) as Feb , rank () over ( order by count ( distinct case monthno when 3 then orderno end ) desc ) as Mar , rank () over ( order by count ( distinct case monthno when 4 then orderno end ) desc ) as Apr , rank () over ( order by count ( distinct case monthno when 5 then orderno end ) desc ) as May , rank () over ( order by count ( distinct case monthno when 6 then orderno end ) desc ) as Jun , rank () over ( order by count ( distinct case monthno when 7 then orderno end ) desc ) as Jul , rank () over ( order by count ( distinct case monthno when 8 then orderno end ) desc ) as Aug , rank () over ( order by count ( distinct case monthno when 9 then orderno end ) desc ) as Sep , rank () over ( order by count ( distinct case monthno when 10 then orderno end ) desc ) as Oct , rank () over ( order by count ( distinct case monthno when 11 then orderno end ) desc ) as Nov , rank () over ( order by count ( distinct case monthno when 12 then orderno end ) desc ) as Dec from dimDate left join factSales on orderdate = dat where year = 2016 group by datename ( dw , dat ), datepart ( dw , dat ) order by datepart ( dw , dat ) ; Tsss, that's an odd looking solution. And not really intuitive either. And yet the only thing we did was substitute the count(case ...) for the count(orderdate) in previous solution. If I had to solve this query without having solved the previous one first, I don't think I would have succeeded. That's why it is a very practical and good strategy to always try to solve a simpler version of your query to get some sense of structure and solution direction. It is debatable whether this result set format is the most convenient to base visuals on in charts. Perhaps the unpivoted version below is more suited in Excel: select monthno , monthname , datepart ( dw , dat ) as dyno , datename ( dw , dat ) dy , rank () over ( partition by monthno order by count ( distinct orderno ) desc ) as rnk from dimDate left join factSales on orderdate = dat where year = 2016 group by monthno , monthname , datename ( dw , dat ), datepart ( dw , dat ) order by monthno , datepart ( dw , dat ) ; Because dimDate has additional columns for month number and month name, we can use them in this query. However, there are no additional columns for weekday and weekday number, so we have to calculate them.","title":"18. Weekday ranking"},{"location":"exercisequeries/#19-abc-labeling","text":"Calculate ABC labeling for all product categories. Hint: look at query 15 from the demo series. select catcode , case when percent_rank () over ( order by sum ( linetotal ) desc ) <= 0 . 2 then 'A' when percent_rank () over ( order by sum ( linetotal ) desc ) >= 0 . 7 then 'C' else 'B' end as label from dimProduct p join factSales s on p . prodno = s . prodno group by catcode order by catcode ;","title":"19. ABC labeling"}]}